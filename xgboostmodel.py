# -*- coding: utf-8 -*-
"""XGboostModel.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1owHbe1DOli9UwWKhdBtaZ90yDP1YtBzL
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import numpy as np
import sklearn as sk
from sklearn.model_selection import train_test_split
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score

data = pd.read_csv("/content/drive/My Drive/finch research/without_desc.csv")

data.head()

data.shape

"""###Split train and test dataset"""

onehot_columns = ['home_ownership', 'purpose', 'addr_state', 'initial_list_status', 'application_type', 'disbursement_method','grade', 'pymnt_plan']
onehot_df = data[onehot_columns]
onehot_df = pd.get_dummies(onehot_df, columns = onehot_columns)
score_onehot_drop = data.drop(onehot_columns, axis = 1)
data_encode = pd.concat([score_onehot_drop, onehot_df], axis = 1)

y=data['loan_status']
x=data_encode.loc[:, data_encode.columns != 'loan_status']
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=2)

x.head()

# not use
onehot_columns = ['home_ownership', 'purpose', 'addr_state', 'initial_list_status', 'application_type', 'disbursement_method']
onehot_df = score_df[onehot_columns]
onehot_df = pd.get_dummies(onehot_df, columns = onehot_columns)
score_onehot_drop = score_df.drop(onehot_columns, axis = 1)
score_onehot = pd.concat([score_onehot_drop, onehot_df], axis = 1)

"""### Hyperparameter

1.   Learning rate
"""

k_list=[]
for kkk in np.arange(0.05, 0.30, 0.01):
    xg=XGBClassifier(learning_rate=kkk,
                     n_estimators=100,
                     colsample_bytree = 0.4,
                     subsample = 0.8, 
                     max_depth=7,
                     gamma=10)
    xg.fit(x_train,y_train)
    y_hat=xg.predict(x_test)
    accuracy = accuracy_score(y_test, y_hat)
    k_list.append(accuracy)

index=k_list.index(min(k_list))
grif=np.linspace(0.05, 0.30, num=25)[index]
print(grif)

"""2.   Number of estimators"""

n_list=[]
for kkk in range(100, 1000,10):
    xg=XGBClassifier(learning_rate=grif,
                     n_estimators=kkk,
                     colsample_bytree = 0.4,
                     subsample = 0.8,
                     objective='binary:logistic', 
                     max_depth=7,
                     gamma=10)
    xg.fit(x_train,y_train)
    y_hat=xg.predict(x_test)
    accuracy = accuracy_score(y_test, y_hat)
    n_list.append(accuracy)

index=n_list.index(min(n_list))
grif2=range(100, 1000,10)[index]
print(grif2)
print(min(n_list))

"""3. Subsample (0.8-1)"""

s_list=[]
for kkk in np.linspace(0.8, 1, num=10):
    xg=XGBClassifier(learning_rate=grif,
                     n_estimators=grif2,
                     colsample_bytree = 0.4,
                     subsample = kkk,
                     objective='binary:logistic', 
                     max_depth=7,
                     gamma=10)
    xg.fit(x_train,y_train)
    y_hat=xg.predict(x_test)
    accuracy = accuracy_score(y_test, y_hat)
    s_list.append(accuracy)

index=s_list.index(min(s_list))
grif3=np.linspace(0.8, 1, num=10)[index]
print(grif3)
print(min(s_list))

"""4. Colsample-bytree (0.3-0.8)"""

c_list=[]
for kkk in range(0.3,0.8,num=25):
    xg=XGBClassifier(learning_rate=grif,
                     n_estimators=grif2,
                     colsample_bytree = kkk,
                     subsample = grif3,
                     objective='binary:logistic', 
                     max_depth=7,
                     gamma=10)
    xg.fit(x_train,y_train)
    y_hat=xg.predict(x_test)
    accuracy = accuracy_score(y_test, y_hat)
    c_list.append(accuracy)

index=c_list.index(min(c_list))
grif4=range(0.3,0.8,num=25)[index]
print(grif4)
print(min(c_list))

"""### Fit Model"""

xg=XGBClassifier(learning_rate=grif,
                     n_estimators=grif2,
                     colsample_bytree = grif4,
                     subsample = grif3,
                     objective='binary:logistic', 
                     max_depth=7,
                     gamma=10)
xg.fit(x_train,y_train)
y_hat=xg.predict(x_test)
accuray = accuracy_score(y_test, y_hat)
print(accuracy)